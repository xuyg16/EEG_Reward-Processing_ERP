{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Behavioral manipulation check: mean proportion of wins (low / mid / high)\n",
        "\n",
        "This notebook reproduces the **behavioral** manipulation check from the MATLAB script:\n",
        "- Compute each subject’s mean win rate per task (task==1/2/3), using only valid trials (`early==0 & invalid==0`).\n",
        "- Run a **one-way repeated-measures ANOVA** on the subject×condition matrix (N×3) using your existing `rm_anova_oneway`.\n",
        "- Print per-condition mean and 95% CI (t-based, like MATLAB).\n",
        "\n",
        "✅ You only need to edit the import line for `rm_anova_oneway` and set `BIDS_ROOT`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- USER SETTINGS ---\n",
        "# Path to your BIDS dataset root (the folder that contains sub-XX/beh/...).\n",
        "BIDS_ROOT = r\"/Users/xuyg/GitHub/EEG_Reward-Processing_ERP/ds004147\"  # TODO: change me\n",
        "\n",
        "# Optional: restrict to a subset of subjects (strings or ints). Example:\n",
        "# SUBJECTS = [27, 28, 31]\n",
        "SUBJECTS = None  # None = auto-detect all beh.tsv under BIDS_ROOT\n",
        "\n",
        "# Optional: save a CSV summary\n",
        "SAVE_CSV = True\n",
        "OUT_CSV = r\"behavior_task_winrates.csv\"  # saved in the current working directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- IMPORTS ---\n",
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import sys\n",
        "\n",
        "# --- IMPORT YOUR EXISTING FUNCTION HERE ---\n",
        "# Change this line to wherever rm_anova_oneway lives in your repo.\n",
        "# Examples you might use:\n",
        "# from stats.rewp_robust import rm_anova_oneway\n",
        "# from stats.s11b_stats_utils import rm_anova_oneway\n",
        "# from s11b_stats import rm_anova_oneway\n",
        "from stats.rewp_parametric import rm_anova_oneway  # TODO: edit if needed\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _coerce_outcome_to_01(outcome: pd.Series) -> np.ndarray:\n",
        "    \"\"\"Ensure outcome is 0/1.\n",
        "    - If outcome is already {0,1}, keep.\n",
        "    - If outcome is {-1,1}, map 1->1, -1->0.\n",
        "    - Otherwise: treat outcome>0 as win.\n",
        "    \"\"\"\n",
        "    x = outcome.to_numpy(dtype=float)\n",
        "    x = x[np.isfinite(x)]\n",
        "    u = set(np.unique(x).tolist())\n",
        "    if u.issubset({0, 1}):\n",
        "        return outcome.to_numpy(dtype=float)\n",
        "    if u.issubset({-1, 1}):\n",
        "        return (outcome.to_numpy(dtype=float) == 1).astype(float)\n",
        "    return (outcome.to_numpy(dtype=float) > 0).astype(float)\n",
        "\n",
        "\n",
        "def mean_ci_t(x, alpha=0.05):\n",
        "    \"\"\"Mean and t-based CI (like MATLAB tinv) for a 1D vector.\"\"\"\n",
        "    x = np.asarray(x, float)\n",
        "    x = x[np.isfinite(x)]\n",
        "    n = x.size\n",
        "    if n == 0:\n",
        "        return np.nan, (np.nan, np.nan), 0\n",
        "    m = float(np.mean(x))\n",
        "    if n < 2:\n",
        "        return m, (np.nan, np.nan), n\n",
        "    sd = float(np.std(x, ddof=1))\n",
        "    tval = float(stats.t.ppf(1 - alpha/2, df=n-1))\n",
        "    ci = tval * sd / np.sqrt(n)\n",
        "    return m, (m - ci, m + ci), n\n",
        "\n",
        "\n",
        "def compute_task_winrates_from_beh(beh_path: str | Path):\n",
        "    \"\"\"Return one subject's mean win rate for low/mid/high tasks (valid trials only).\"\"\"\n",
        "    beh_path = Path(beh_path)\n",
        "    df = pd.read_csv(beh_path, sep='\\t')\n",
        "    required = ['task', 'early', 'invalid', 'outcome']\n",
        "    missing = [c for c in required if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"{beh_path} missing columns: {missing}\")\n",
        "\n",
        "    valid = (df['early'] == 0) & (df['invalid'] == 0)\n",
        "    out01 = _coerce_outcome_to_01(df['outcome'])\n",
        "\n",
        "    def _grab(task_id: int):\n",
        "        mask = (df['task'] == task_id) & valid\n",
        "        vals = out01[mask.to_numpy()]\n",
        "        return float(np.nanmean(vals)) if vals.size else np.nan, int(vals.size)\n",
        "\n",
        "    low, n_low = _grab(1)\n",
        "    mid, n_mid = _grab(2)\n",
        "    high, n_high = _grab(3)\n",
        "\n",
        "    return {\n",
        "        'low': low, 'mid': mid, 'high': high,\n",
        "        'n_low': n_low, 'n_mid': n_mid, 'n_high': n_high,\n",
        "        'beh_path': str(beh_path),\n",
        "    }\n",
        "\n",
        "\n",
        "def collect_all_subject_task_winrates(bids_root: str | Path, subjects=None):\n",
        "    \"\"\"Collect low/mid/high winrates for all subjects (or a provided subset).\"\"\"\n",
        "    bids_root = Path(bids_root)\n",
        "\n",
        "    if subjects is None:\n",
        "        beh_files = sorted(bids_root.rglob('sub-*_task-casinos_beh.tsv'))\n",
        "    else:\n",
        "        beh_files = []\n",
        "        for s in subjects:\n",
        "            s_str = f\"{int(s):02d}\" if str(s).isdigit() else str(s)\n",
        "            beh_files.append(bids_root / f\"sub-{s_str}\" / 'beh' / f\"sub-{s_str}_task-casinos_beh.tsv\")\n",
        "        beh_files = [p for p in beh_files if p.exists()]\n",
        "\n",
        "    if not beh_files:\n",
        "        raise FileNotFoundError(f\"No beh.tsv found under {bids_root}\")\n",
        "\n",
        "    rows = []\n",
        "    for p in beh_files:\n",
        "        # subject id from path parts like .../sub-27/beh/...\n",
        "        sub = next((x.replace('sub-','') for x in p.parts if x.startswith('sub-')), None)\n",
        "        res = compute_task_winrates_from_beh(p)\n",
        "        rows.append({'subject': sub, **res})\n",
        "\n",
        "    df = pd.DataFrame(rows).sort_values('subject').reset_index(drop=True)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>low</th>\n",
              "      <th>mid</th>\n",
              "      <th>high</th>\n",
              "      <th>n_low</th>\n",
              "      <th>n_mid</th>\n",
              "      <th>n_high</th>\n",
              "      <th>beh_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27</td>\n",
              "      <td>0.507042</td>\n",
              "      <td>0.563380</td>\n",
              "      <td>0.566434</td>\n",
              "      <td>142</td>\n",
              "      <td>142</td>\n",
              "      <td>143</td>\n",
              "      <td>/Users/xuyg/GitHub/EEG_Reward-Processing_ERP/d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28</td>\n",
              "      <td>0.534722</td>\n",
              "      <td>0.661972</td>\n",
              "      <td>0.638889</td>\n",
              "      <td>144</td>\n",
              "      <td>142</td>\n",
              "      <td>144</td>\n",
              "      <td>/Users/xuyg/GitHub/EEG_Reward-Processing_ERP/d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29</td>\n",
              "      <td>0.440860</td>\n",
              "      <td>0.507812</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>93</td>\n",
              "      <td>128</td>\n",
              "      <td>120</td>\n",
              "      <td>/Users/xuyg/GitHub/EEG_Reward-Processing_ERP/d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30</td>\n",
              "      <td>0.453237</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.492647</td>\n",
              "      <td>139</td>\n",
              "      <td>138</td>\n",
              "      <td>136</td>\n",
              "      <td>/Users/xuyg/GitHub/EEG_Reward-Processing_ERP/d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31</td>\n",
              "      <td>0.485915</td>\n",
              "      <td>0.559441</td>\n",
              "      <td>0.721429</td>\n",
              "      <td>142</td>\n",
              "      <td>143</td>\n",
              "      <td>140</td>\n",
              "      <td>/Users/xuyg/GitHub/EEG_Reward-Processing_ERP/d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  subject       low       mid      high  n_low  n_mid  n_high  \\\n",
              "0      27  0.507042  0.563380  0.566434    142    142     143   \n",
              "1      28  0.534722  0.661972  0.638889    144    142     144   \n",
              "2      29  0.440860  0.507812  0.500000     93    128     120   \n",
              "3      30  0.453237  0.565217  0.492647    139    138     136   \n",
              "4      31  0.485915  0.559441  0.721429    142    143     140   \n",
              "\n",
              "                                            beh_path  \n",
              "0  /Users/xuyg/GitHub/EEG_Reward-Processing_ERP/d...  \n",
              "1  /Users/xuyg/GitHub/EEG_Reward-Processing_ERP/d...  \n",
              "2  /Users/xuyg/GitHub/EEG_Reward-Processing_ERP/d...  \n",
              "3  /Users/xuyg/GitHub/EEG_Reward-Processing_ERP/d...  \n",
              "4  /Users/xuyg/GitHub/EEG_Reward-Processing_ERP/d...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subjects with complete low/mid/high winrates: 12 / 12\n"
          ]
        }
      ],
      "source": [
        "# --- LOAD & COMPUTE WINRATES ---\n",
        "df = collect_all_subject_task_winrates(BIDS_ROOT, subjects=SUBJECTS)\n",
        "display(df.head())\n",
        "\n",
        "X = df[['low', 'mid', 'high']].to_numpy(float)\n",
        "mask = np.all(np.isfinite(X), axis=1)\n",
        "df_use = df.loc[mask].reset_index(drop=True)\n",
        "X_use = X[mask]\n",
        "\n",
        "print(f\"Subjects with complete low/mid/high winrates: {df_use.shape[0]} / {df.shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "low-value: 48.60%, 95% CI [46.71, 50.50] (n=12)\n",
            "mid-value: 59.03%, 95% CI [55.78, 62.28] (n=12)\n",
            "high-value: 60.00%, 95% CI [54.08, 65.92] (n=12)\n"
          ]
        }
      ],
      "source": [
        "# --- REPORT MEANS + 95% CI (like MATLAB) ---\n",
        "for name in ['low', 'mid', 'high']:\n",
        "    m, (lo, hi), n = mean_ci_t(df_use[name].to_numpy(float))\n",
        "    m, lo, hi = m*100, lo*100, hi*100\n",
        "    print(f\"{name}-value: {m:.2f}%, 95% CI [{lo:.2f}, {hi:.2f}] (n={n})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normality var 1: met (p=0.8828)\n",
            "Normality var 2: met (p=0.1956)\n",
            "Normality var 3: met (p=0.9466)\n",
            "RM ANOVA: F(2,22) = 14.08, p = 0.0001155\n",
            "partial eta^2 = 0.5614\n",
            "generalized eta^2 = 0.4168\n",
            "Friedman: chi2 = 15.17, p = 0.0005089\n",
            "\n",
            "Returned dict: {'F': 14.080137126897442, 'p': 0.00011552888001464812, 'df1': 2, 'df2': 22, 'partial_eta2': 0.5614059068200651, 'generalized_eta2': 0.4167876866125043, 'friedman_chi2': 15.166666666666657, 'friedman_p': 0.0005088621855732938, 'friedman_n': 12}\n",
            "F(2,22) = 14.08, p < .001, ηp² = 0.56, ηg² = 0.42\n"
          ]
        }
      ],
      "source": [
        "# --- RUN ONE-WAY REPEATED-MEASURES ANOVA (your existing function) ---\n",
        "anova_res = rm_anova_oneway(X_use)\n",
        "print(\"\\nReturned dict:\", anova_res)\n",
        "\n",
        "# Pretty one-liner similar to paper\n",
        "df1, df2 = anova_res.get('df1'), anova_res.get('df2')\n",
        "F, p = anova_res.get('F'), anova_res.get('p')\n",
        "etap, etag = anova_res.get('partial_eta2'), anova_res.get('generalized_eta2')\n",
        "if p is not None and np.isfinite(p) and p < 0.001:\n",
        "    p_str = \"< .001\"\n",
        "else:\n",
        "    p_str = f\"= {p:.4g}\" if p is not None else \"= ?\"\n",
        "print(f\"F({df1},{df2}) = {F:.2f}, p {p_str}, ηp² = {etap:.2f}, ηg² = {etag:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: /Users/xuyg/GitHub/EEG_Reward-Processing_ERP/scripts/behavior_task_winrates.csv\n"
          ]
        }
      ],
      "source": [
        "# --- OPTIONAL: SAVE SUBJECT-LEVEL WINRATES ---\n",
        "if SAVE_CSV:\n",
        "    out = Path(OUT_CSV)\n",
        "    df_use[['subject','low','mid','high','n_low','n_mid','n_high','beh_path']].to_csv(out, index=False)\n",
        "    print(\"Saved:\", out.resolve() if out.exists() else out)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "eeg_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
